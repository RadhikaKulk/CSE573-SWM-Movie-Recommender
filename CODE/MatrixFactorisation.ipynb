{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0at3yzYMQCY8",
    "outputId": "8b5d4304-9a85-4640-b7ca-433e44bc9fce"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yb/997fk6x95p1fw1qgz6gml1yw0000gn/T/ipykernel_9972/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOnK8F1dLR6F",
    "outputId": "21a7e091-dc47-4ed8-c34e-7688fdc3151c"
   },
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install scikit-surprise\n",
    "import os\n",
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "from collections import defaultdict\n",
    "from surprise import KNNBasic\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import accuracy\n",
    "from surprise import AlgoBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "n5M280SQLR6F",
    "outputId": "ca204db3-ce02-418e-9e80-5ad526ceab6c"
   },
   "outputs": [],
   "source": [
    "# Reading the file ratings and storing it in a dataframe\n",
    "ratings = pd.read_csv('/content/drive/MyDrive/data/ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xXNM77ULR6G",
    "outputId": "eafd3403-73a6-4474-f2f0-ed76a7f62839"
   },
   "outputs": [],
   "source": [
    "ratings_map = {}\n",
    "ratings_map['itemID'] = list(ratings.movieId)\n",
    "ratings_map['userID'] = list(ratings.userId)\n",
    "ratings_map['rating'] = list(ratings.rating)\n",
    "\n",
    "df = pd.DataFrame(ratings_map)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2AxjWMMLR6H",
    "outputId": "5f9aecdf-a1c4-4e63-9127-fede4854e15f"
   },
   "outputs": [],
   "source": [
    "# Create 5 folds\n",
    "from surprise.model_selection import KFold\n",
    "rr = Reader(rating_scale=(0.5, 5.0))\n",
    "rating_map_keys = ['userID', 'itemID', 'rating']\n",
    "filter = df[rating_map_keys]\n",
    "data = Dataset.load_from_df(filter, rr)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "kf.split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REzUl20Djatm"
   },
   "outputs": [],
   "source": [
    "# class to predict ratings using a standard stochastic gradient descent algo\n",
    "class SGDMatixSelf(AlgoBase):\n",
    "    '''A basic rating prediction algorithm based on matrix factorization.'''\n",
    "    \n",
    "    def __init__(self, l_r, n_e, n_f):\n",
    "        self.n_f = n_f\n",
    "        self.n_e = n_e\n",
    "        self.lr = l_r\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        # print('Fit started')\n",
    "        \n",
    "        p = np.random.normal(0, .1, (trainset.n_users, self.n_f))\n",
    "        q = np.random.normal(0, .1, (trainset.n_items, self.n_f))\n",
    "        \n",
    "        for z in range(self.n_e):\n",
    "            for i, j, k in trainset.all_ratings():\n",
    "                e = k - np.dot(p[i], q[j])\n",
    "                p[i] = p[i] + q[j] * e * self.lr\n",
    "                q[j] = q[j] + p[i] * e * self.lr\n",
    "        \n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.trainset = trainset\n",
    "\n",
    "    def estimate(self, i, j):\n",
    "        if  self.trainset.knows_user(i) and self.trainset.knows_item(j):\n",
    "            return np.dot(self.p[i], self.q[j])\n",
    "        else:\n",
    "            return self.trainset.global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gd5cZoVRLR6J",
    "outputId": "f34f98b5-24e4-40b8-8bef-24a9361ccb47"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#removing timestamp\n",
    "rating_map_keys = ['userID', 'itemID', 'rating']\n",
    "filter = df[rating_map_keys]\n",
    "data = Dataset.load_from_df(filter, reader)\n",
    "\n",
    "eval = []\n",
    "for i in [SGDMatixSelf(.01, 10,10),SVD(), NMF(), KNNBasic()]:\n",
    "    cva = cross_validate(i, data, measures=['RMSE'], cv=4, verbose=False)\n",
    "    tempdataframe = pd.DataFrame.from_dict(cva).mean(axis=0)\n",
    "    algoSplitArray = str(i).split(' ')\n",
    "    finalAlgoSplitArray = algoSplitArray[0].split('.')\n",
    "    tempdataframe.append(pd.Series([finalAlgoSplitArray[-1]],index=['Algorithm']))\n",
    "    eval.append(tempdataframe)\n",
    "\n",
    "                     \n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6PJgi_YLR6K",
    "outputId": "05381bd5-a1df-480b-a43f-f25ac348dcad"
   },
   "outputs": [],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHpMhgd1LR6K"
   },
   "outputs": [],
   "source": [
    "# Grid search to find best hyperparameter, commented as takes longer time\n",
    "# grid_options = {'n_factors': [10, 15, 20, 30], 'n_epochs': [10, 20, 30], 'lr_all': [0.002, 0.005, 0.008, 0.01],\n",
    "#               'reg_all': [0.08, 0.1, 0.12]}\n",
    "# search = GridSearchCV(SVD, grid_options, measures=['rmse'], cv=3)\n",
    "# search.fit(data)\n",
    "# algo = search.best_estimator['rmse']\n",
    "# print(search.best_score['rmse'])\n",
    "# print(search.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OO7m3Jq3LR6L",
    "outputId": "dff683fa-1b27-4428-b8bd-6928a6c4b476"
   },
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "algo = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6idqGD2xBTVM",
    "outputId": "09fd8f25-45f5-4e34-82d0-870c0c02ec28"
   },
   "outputs": [],
   "source": [
    "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irTcV744k9iN"
   },
   "outputs": [],
   "source": [
    "# algo1 = KNNBasic(n_factors=30, n_epochs=20)\n",
    "# predictions2 = algo1.fit(trainset).test(testset)\n",
    "# accuracy.rmse(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHqV83kHlrVt"
   },
   "outputs": [],
   "source": [
    "# predictions.sort()\n",
    "# predictions2.sort()\n",
    "# rui = []\n",
    "# p1 = []\n",
    "# p2 = []\n",
    "# for i in predictions:\n",
    "#   rui.append(i[2])\n",
    "#   p1.append(i[3])\n",
    "\n",
    "# for j in predictions2:\n",
    "#   p2.append(j[3])\n",
    "\n",
    "# p1 = [x * 0.6 for x in p1]\n",
    "# p2 = [x * 0.3 for x in p2]\n",
    "# fin = [sum(x) for x in zip(p1, p2)]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nb9hWk_7oVHa"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def rmse(predictions, targets):\n",
    "#     return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "# rmse(np.array(fin),np.array(rui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MuQFLRT9LR6M"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "\n",
    "    userid_to_estimate_map = defaultdict(list)\n",
    "    for user_id, _, ratings_true, estimate_value, _ in predictions:\n",
    "        userid_to_estimate_map[user_id].append((estimate_value, ratings_true))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for user_id, user_ratings in userid_to_estimate_map.items():\n",
    "\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        n_rel = sum((ratings_true >= threshold) for (_, ratings_true) in user_ratings)\n",
    "\n",
    "        n_rec_k = sum((estimate_value >= threshold) for (estimate_value, _) in user_ratings[:k])\n",
    "\n",
    "        n_rel_and_rec_k = sum(((ratings_true >= threshold) and (estimate_value >= threshold))\n",
    "                              for (estimate_value, ratings_true) in user_ratings[:k])\n",
    "\n",
    "        precisions[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        recalls[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_oo0ENtLR6N",
    "outputId": "c620edd1-1e8f-4940-cb5c-8e749a0ab90b"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4)\n",
    "\n",
    "algo = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
    "i = 1\n",
    "for trainset, testset in kf.split(data):\n",
    "    print(\"Split:\", i)\n",
    "    predictions = algo.fit(trainset).test(testset)\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
    "\n",
    "    print(\"Precision:\", sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    print(\"Recall:\", sum(rec for rec in recalls.values()) / len(recalls))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWZFtneRLR6P"
   },
   "outputs": [],
   "source": [
    "def getpreds(predictions):\n",
    "    \n",
    "    fin = defaultdict(list)    \n",
    "    for user_id, id, ratings_true, estimate_value, _ in predictions:\n",
    "        fin[user_id].append((id, estimate_value))\n",
    "\n",
    "    for user_id, user_ratings in fin.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_9iNHxcLR6P"
   },
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "algo = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
    "algo.fit(trainset)\n",
    "\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "all_pred = getpreds(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPIs8RLYLR6P"
   },
   "source": [
    "#### Now as we have all the predicted rating, We'll subset to only top \" \" movies for every user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtGv8nBILR6P"
   },
   "outputs": [],
   "source": [
    "#setting recommendation size to 10\n",
    "n = 10\n",
    "\n",
    "for user_id, user_ratings in all_pred.items():\n",
    "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    all_pred[user_id] = user_ratings[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1htdMyTK8H8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mw29KYZLR6P"
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame.from_dict(all_pred)\n",
    "tmp_transpose = tmp.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vshQIydu03oI"
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for user_id,user_ratings in all_pred.items():\n",
    "  res.append(tmp_transpose.loc[user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "929brbV11KgW"
   },
   "outputs": [],
   "source": [
    "#movieids of reommended movies\n",
    "recomml = []\n",
    "for i in res:\n",
    "  recommended_movie_ids=[]\n",
    "  for x in range(0, n):\n",
    "    recommended_movie_ids.append(i[x][0])\n",
    "  recomml.append(recommended_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ySjr1Cmd5Zz",
    "outputId": "d28a193d-6242-429b-af39-ae10f3dff74d"
   },
   "outputs": [],
   "source": [
    "recomml[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNrNbwMQd7sr",
    "outputId": "5d175296-73b0-4093-d35f-69874df53044"
   },
   "outputs": [],
   "source": [
    "finall[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfGbme3v1QxZ"
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('/content/drive/MyDrive/data/movies.csv')\n",
    "finall = []\n",
    "for i in recomml:\n",
    "  df = movies[movies['movieId'].isin(i)]\n",
    "  temp = df['title'].tolist()\n",
    "  finall.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIU_ncsnME7r"
   },
   "outputs": [],
   "source": [
    "fin = pd.DataFrame(finall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uBuXLF6Myrq"
   },
   "outputs": [],
   "source": [
    "#Saving recommendations to a file\n",
    "fin.to_csv('/content/drive/MyDrive/data/file2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdBzj1SENQ-L"
   },
   "outputs": [],
   "source": [
    "r = pd.read_csv('/content/drive/MyDrive/data/file2.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gjXqv71vLR6K",
    "6draSSY4LR6N"
   ],
   "name": "MovieLens_100K_Recommeder_System_SVD_checkpoint (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
